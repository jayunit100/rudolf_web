<h1>Parsing Beagle: part 1</h1>

<hr>
<h3>What is Beagle?</h3>

<p>Beagle is a simple dialect of Lisp.  It is hosted on Github
<a href="https://github.com/mattfenwick/Beagle">here</a>.</p>

<p>Lisps are very easy to parse, due to their use of parentheses.
Parentheses are possibly both the most popular -- because of its uniformity --
and most hated -- because of its ugliness -- feature of Lisp, and
definitely the most visually distinctive!</p>

<p>Parsing is often seen as a black art, involving heavy-duty parser generators,
complicated BNF grammars, abstract syntax trees, symbol tables ....</p>

<p>Much of this is due to the fact that most programming languages have 
very difficult syntax.</p>

<p>My goal in writing this article is to give a clear, practical, and useful
explanation for how to build a parser.  Using a Lisp as an example language
helps keep the discussion simple without creating a need to resort to 
hand-waving.</p>

<p>Thus, in this article, we'll see the basic steps for how to transform a string
of characters into an abstract, executable representation of code.</p>

<h3>
<a name="parsing-overview" class="anchor" href="#parsing-overview"><span class="mini-icon mini-icon-link"></span></a>Parsing overview</h3>

<p>The goal of parsing is to transform human- or computer-generated input text -- 
into something the computer can understand and execute.</p>

<p>This is often broken down into 3 main steps:</p>

<ol>
<li><p>lexing (AKA tokenization or scanning):  convert an input string into tokens.  </p></li>
<li><p>throw away tokens such as whitespace and comments that do not
contribute to the executable code</p></li>
<li><p>syntactic analysis:  assemble the tokens to form phrases and sentences</p></li>
</ol><p>For the rest of this article, we'll use this simple example to demonstrate
import concepts:</p>

<pre class="code"><code>(define x "hi")
</code></pre>

<h3>
<a name="stage-1-lexing" class="anchor" href="#stage-1-lexing"><span class="mini-icon mini-icon-link"></span></a>Stage 1: Lexing</h3>

<p>Here are Beagle's token definitions:</p>

<pre class="code"><code>STRING:         "[^\"]*"

SYMBOL:         [^;\"\(\)\s]+

OPEN:           (

CLOSE:          )

WHITESPACE:     /^\s+/

COMMENT:        /^;+(.*)/
</code></pre>

<p><em>(We'll write token names in all caps to distinguish them).</em></p>

<p>Now, just a quick reminder:  the input for lexing is a string, and the output is a list
of tokens.  So, using the above token definitions, we'll go through the string
<code>(define x 4)</code> and match the text to individual tokens.</p>

<p>As it happens, there are 7 tokens:</p>

<pre class="code"><code>['(', 'define', ' ', 'x', ' ', '"hi"', ')']
</code></pre>

<p>But how do we get that answer?</p>

<ol>
<li><p>the first character is <code>(</code> -- this matches the <code>OPEN</code> token</p></li>
<li><p>the next characters -- <code>define</code> -- aren't semicolons, open or close parentheses,
or whitespace, and so they match the <code>SYMBOL</code> token</p></li>
<li><p>a single space matches <code>WHITESPACE</code></p></li>
<li><p><code>x</code> is a <code>SYMBOL</code> token (see 2. for explanation)</p></li>
<li><p><code>WHITESPACE</code> (see 3.)</p></li>
<li><p>if it starts with a <code>"</code> mark, it must be a <code>STRING</code> token</p></li>
<li><p>a <code>)</code> is a CLOSE</p></li>
</ol><p>Note that our answer is unique -- when I created the token definitions, I tried
to make sure that there was never any possibility for ambiguity when tokenizing
a string.</p>

<h3>
<a name="stage-2-get-rid-of-unwanted-tokens" class="anchor" href="#stage-2-get-rid-of-unwanted-tokens"><span class="mini-icon mini-icon-link"></span></a>Stage 2: get rid of unwanted tokens</h3>

<p>We don't need the comments or the whitespace for syntac analysis (although they would be
useful to a tool that generates web-based documentation from a source code file, for
instance), so let's get rid of them, leaving us with these tokens:</p>

<pre class="code"><code>["(", "define", "x", "4", ")"]
</code></pre>

<h3>
<a name="stage-3-syntactic-analysis-" class="anchor" href="#stage-3-syntactic-analysis-"><span class="mini-icon mini-icon-link"></span></a>Stage 3: Syntactic analysis ###</h3>

<p>In this step, we assemble the tokens according to our grammar, which is:</p>

<pre class="code"><code>BeagleCode:     SExpression(+)

SExpression:    Atom  |  List

List:           OPEN  SExpression(*)  CLOSE

Atom:           STRING  |  SYMBOL
</code></pre>

<p><em>(Remember that tokens are in all caps -- these productions have only leading caps).</em></p>

<p>Basically, the grammar says that Beagle code is a bunch of s-expressions,
and that s-expressions can be atoms or lists.  An atom is either a string or a 
symbol, and a list is an open-paren and a close-paren surrounding any number
of s-expressions (so the grammar is recursive).</p>

<p>We can match this grammar to our tokens using a strategy called "recursive descent".
Let's try it ourselves:</p>

<pre class="code"><code>1. try BeagleCode
 2. try SExpression
  3. try Atom
   4. try STRING ... failed
   5. try SYMBOL ... failed
  6. try List
   7. try OPEN ... succeeded (matched `(`)
   8. try SExpression
    9. try Atom
     10. try STRING ... failed
     11. try SYMBOL ... succeeded (matched `define`)
   12. try SExpression
    13. try ATOM
     14. try STRING ... failed
     15. try SYMBOL ... succeeded (matched `x`)
   16. try SExpression
    17. try ATOM
     18. try STRING ... succeeded (matched `hi`)
   19. try SExpression
    20. try ATOM
     21. try STRING ... failed
     22. try SYMBOL ... failed
    21. try LIST
     23. try OPEN ... failed
   24. try CLOSE ... succeeded (matched `)`)
  &lt;matched List&gt;
 &lt;matched SExpression&gt;
&lt;matched BeagleCode&gt; 
</code></pre>

<p>Cool, it worked!  Our parse tree now looks like: </p>

<pre class="code"><code>list: 
  symbol: define 
  symbol: x 
  string: hi
</code></pre>

<h3>
<a name="dealing-with-faulty-input" class="anchor" href="#dealing-with-faulty-input"><span class="mini-icon mini-icon-link"></span></a>Dealing with faulty input</h3>

<p>Real-world (read: useful) parsers will have to deal with problems such as:</p>

<ul>
<li><p>error-detection</p></li>
<li><p>error messages</p></li>
<li><p>error-tolerance</p></li>
</ul><p>I've heard it said that dealing with errors accounts for ~80% of the code in
typical projects, and indeed, this is no exception, so let's skip it. :)</p>

<h3>
<a name="summary" class="anchor" href="#summary"><span class="mini-icon mini-icon-link"></span></a>Summary</h3>

<p>What did we do?  We saw that parsing can be split into:</p>

<ul>
<li><p>tokenizing a string, using regular expressions</p></li>
<li><p>discarding uninteresting tokens</p></li>
<li><p>assembling tokens into a parse tree, using a grammar</p></li>
</ul><p>These are the basics of parsing.  Extending the examples to parse Javascript will
be left as an exercise for the reader!</p>